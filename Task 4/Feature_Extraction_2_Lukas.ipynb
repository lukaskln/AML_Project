{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from scipy import integrate\r\n",
        "from biosppy.signals import eeg\r\n",
        "from scipy.signal import find_peaks,peak_prominences,peak_widths,periodogram\r\n",
        "from scipy.stats import kurtosis,skew\r\n",
        "from sklearn.decomposition import PCA \r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "\r\n",
        "def StatFeature(arrays):\r\n",
        "    mean = np.mean(arrays)\r\n",
        "    std = np.std(arrays)\r\n",
        "    maxv = np.max(arrays)\r\n",
        "    minv = np.min(arrays)\r\n",
        "    return [mean,std,maxv, minv]\r\n",
        "\r\n",
        "\r\n",
        "def findLFHF(psd, w):\r\n",
        "    VLFpsd = VLFw = LFpsd = LFw = HFpsd = HFw = np.empty(0)\r\n",
        "    m = w.shape[0]\r\n",
        "\r\n",
        "    for i in range(0, m):\r\n",
        "        if w[i] <= 0.05:\r\n",
        "            VLFpsd = np.append(VLFpsd, psd[i])\r\n",
        "            VLFw = np.append(VLFw, w[i])\r\n",
        "        if w[i] > 0.05 and w[i] <= 0.15:\r\n",
        "            LFpsd = np.append(LFpsd, psd[i])\r\n",
        "            LFw = np.append(LFw, w[i])\r\n",
        "        if w[i] > 0.15 and w[i] <= 0.4:\r\n",
        "            HFpsd = np.append(HFpsd, psd[i])\r\n",
        "            HFw = np.append(HFw, w[i])\r\n",
        "\r\n",
        "    LF = integrate.trapz(LFw, LFpsd) / (integrate.trapz(w, psd) - integrate.trapz(VLFw, VLFpsd))\r\n",
        "    HF = integrate.trapz(HFw, HFpsd) / (integrate.trapz(w, psd) - integrate.trapz(VLFw, VLFpsd))\r\n",
        "    LFHFratio = LF / HF\r\n",
        "    inter = LF / (LF + HF)\r\n",
        "    if HFpsd.size:\r\n",
        "        [maxHFD, maxIndex] = max((v, i) for i, v in enumerate(HFpsd))\r\n",
        "        FreqmaxP = HFw[maxIndex]\r\n",
        "    else:\r\n",
        "        maxHFD = 0\r\n",
        "        FreqmaxP = 0\r\n",
        "    return (LF, HF, FreqmaxP, maxHFD, LFHFratio, inter)\r\n",
        "\r\n",
        "\r\n",
        "def EMGFeatures(raw_signal, fs=128):\r\n",
        "    # Statistical Features\r\n",
        "    [_,std,maxv,minv] = StatFeature(raw_signal)\r\n",
        "    \r\n",
        "    # Power Spectrum\r\n",
        "    w = np.hamming(len(raw_signal))\r\n",
        "    w, psd = periodogram(raw_signal, window=w, detrend=False)\r\n",
        "    _, _, _, maxHFD, _, _ = findLFHF(psd, w)\r\n",
        "    \r\n",
        "    # Time Series\r\n",
        "    kurt = kurtosis(raw_signal)\r\n",
        "    sk = skew(raw_signal)\r\n",
        "        \r\n",
        "    # Peak Features\r\n",
        "    [peaks,_] = find_peaks(raw_signal)\r\n",
        "    pprom = peak_prominences(raw_signal,peaks)[0]\r\n",
        "    contour_heights = raw_signal[peaks] - pprom\r\n",
        "    pwid = peak_widths(raw_signal,peaks,rel_height=0.4)[0]\r\n",
        "    [ppmean,ppstd,_,ppmin] = StatFeature(pprom)\r\n",
        "    [pwmean,pwstd,pwmax,pwmin] = StatFeature(pwid)\r\n",
        " \r\n",
        "    return np.array([std,maxv,minv,maxHFD, kurt,sk,ppmean,ppstd,ppmin,pwmean,pwstd,pwmax,pwmin])\r\n",
        "\r\n",
        "\r\n",
        "def EEGFeatures(raw_signal,signal_1,signal_2, fs=128):\r\n",
        "    bio_signal = np.transpose(raw_signal)\r\n",
        "        \r\n",
        "    # Statistical Features\r\n",
        "    [_,std1,maxv1,minv1] = StatFeature(signal_1)\r\n",
        "    [_,std2,maxv2,minv2] = StatFeature(signal_2)    \r\n",
        "        \r\n",
        "    # Power Features\r\n",
        "    [_, theta, alpha_low,alpha_high,beta, gamma]= eeg.get_power_features(signal=bio_signal, sampling_rate=fs)\r\n",
        "        \r\n",
        "    [theta1_mean,theta1_std,theta1_max,theta1_min] = StatFeature(theta[:,0])\r\n",
        "    [theta2_mean,theta2_std,theta2_max,theta2_min] = StatFeature(theta[:,1])\r\n",
        "    [alpha_low1_mean,alpha_low1_std,alpha_low1_max,alpha_low1_min] = StatFeature(alpha_low[:,0])\r\n",
        "    [alpha_low2_mean,alpha_low2_std,alpha_low2_max,alpha_low2_min] = StatFeature(alpha_low[:,1])\r\n",
        "    [alpha_high1_mean,alpha_high1_std,alpha_high1_max,alpha_high1_min] = StatFeature(alpha_high[:,0])\r\n",
        "    [alpha_high2_mean,alpha_high2_std,alpha_high2_max,alpha_high2_min] = StatFeature(alpha_high[:,1])\r\n",
        "    [beta1_mean,beta1_std,beta1_max,beta1_min] = StatFeature(beta[:,0])\r\n",
        "    [beta2_mean,beta2_std,beta2_max,beta2_min] = StatFeature(beta[:,1])\r\n",
        "    [gamma1_mean,gamma1_std,gamma1_max,gamma1_min] = StatFeature(gamma[:,0])\r\n",
        "    [gamma2_mean,gamma2_std,gamma2_max,gamma2_min] = StatFeature(gamma[:,1])\r\n",
        "        \r\n",
        "        \r\n",
        "    # Power Spectrum\r\n",
        "    w = np.hamming(len(signal_1))\r\n",
        "    w, psd = periodogram(signal_1, window=w, detrend=False)\r\n",
        "    _, _, FreqmaxP1, _, _, _ = findLFHF(psd, w)\r\n",
        "    w = np.hamming(len(signal_2))\r\n",
        "    w, psd = periodogram(signal_2, window=w, detrend=False)\r\n",
        "    _, _, FreqmaxP2, _, _, _ = findLFHF(psd, w)\r\n",
        "        \r\n",
        "    # Time Series\r\n",
        "    kurt1 = kurtosis(signal_1)\r\n",
        "    skew1 = skew(signal_1)\r\n",
        "    kurt2 = kurtosis(signal_2)\r\n",
        "    skew2 = skew(signal_2)\r\n",
        "        \r\n",
        "    # Peak Features\r\n",
        "    [peaks1,_] = find_peaks(signal_1)\r\n",
        "    pprom1 = peak_prominences(signal_1,peaks1)[0]\r\n",
        "    contour_heights1 = signal_1[peaks1] - pprom1\r\n",
        "    pwid1 = peak_widths(signal_1,peaks1,rel_height=0.4)[0]\r\n",
        "    [ppmean1,ppstd1,_,ppmin1] = StatFeature(pprom1)\r\n",
        "    [pwmean1,pwstd1,pwmax1,pwmin1] = StatFeature(pwid1)\r\n",
        "        \r\n",
        "    [peaks2,_] = find_peaks(signal_2)\r\n",
        "    pprom2 = peak_prominences(signal_2,peaks2)[0]\r\n",
        "    contour_heights2 = signal_2[peaks2] - pprom2\r\n",
        "    pwid2 = peak_widths(signal_2,peaks2,rel_height=0.4)[0]\r\n",
        "    [ppmean2,ppstd2,_,ppmin2] = StatFeature(pprom2)\r\n",
        "    [pwmean2,pwstd2,pwmax2,pwmin2] = StatFeature(pwid2)\r\n",
        " \r\n",
        "    return np.array([theta1_mean,theta1_std,theta1_max,theta1_min, theta2_mean,theta2_std,theta2_max,theta2_min, alpha_low1_mean,alpha_low1_std,alpha_low1_max,alpha_low1_min,alpha_low2_mean,alpha_low2_std,alpha_low2_max,alpha_low2_min,alpha_high1_mean,alpha_high1_std,alpha_high1_max,alpha_high1_min,alpha_high2_mean,alpha_high2_std,alpha_high2_max,alpha_high2_min,beta1_mean,beta1_std,beta1_max,beta1_min,beta2_mean,beta2_std,beta2_max,beta2_min,gamma1_mean,gamma1_std,gamma1_max,gamma1_min,gamma2_mean,gamma2_std,gamma2_max,gamma2_min,FreqmaxP1,kurt1,skew1,ppmean1,ppstd1,ppmin1,pwmean1,pwstd1,pwmax1,pwmin1,FreqmaxP2,kurt2,skew2,ppmean2,ppstd2,ppmin2,pwmean2,pwstd2,pwmax2,pwmin2,std1,maxv1,minv1,std2,maxv2,minv2])\r\n",
        "\r\n",
        "\r\n",
        "def ExtractFeatures(eeg1,eeg2,emg, fs=128):\r\n",
        "    raw_signal = np.concatenate(([eeg1],[eeg2]))\r\n",
        "    feature1 = EEGFeatures(raw_signal,eeg1,eeg2,fs=fs)\r\n",
        "    feature2 = EMGFeatures(emg)\r\n",
        "    return np.concatenate((feature1, feature2))"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1607273746309
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Import ####\r\n",
        "\r\n",
        "column_names_x = ['id']\r\n",
        "for i in range(512):\r\n",
        "  column_names_x.append('x'+str(i))\r\n",
        "\r\n",
        "raw_dataset_x_1 = pd.read_csv('train_eeg1.csv', names=column_names_x,\r\n",
        "                     na_values = \"?\", comment='\\t',\r\n",
        "                     sep=\",\", skipinitialspace=True, skiprows=True)\r\n",
        "\r\n",
        "dataset_x_1 = raw_dataset_x_1.copy()\r\n",
        "dataset_x_1.tail()\r\n",
        "dataset_x_1.pop(\"id\")\r\n",
        "\r\n",
        "raw_dataset_x_2 = pd.read_csv('train_eeg2.csv', names=column_names_x,\r\n",
        "                     na_values = \"?\", comment='\\t',\r\n",
        "                     sep=\",\", skipinitialspace=True, skiprows=True)\r\n",
        "\r\n",
        "dataset_x_2 = raw_dataset_x_2.copy()\r\n",
        "dataset_x_2.tail()\r\n",
        "dataset_x_2.pop(\"id\")\r\n",
        "\r\n",
        "dataset_x_1 = np.array(dataset_x_1)\r\n",
        "dataset_x_2 = np.array(dataset_x_2)\r\n",
        "\r\n",
        "column_names_y = ['id','y']\r\n",
        "raw_dataset_y = pd.read_csv('train_labels.csv', names=column_names_y,\r\n",
        "                    na_values = \"?\", comment='\\t',\r\n",
        "                    sep=\",\", skipinitialspace=True, skiprows=True)\r\n",
        "\r\n",
        "dataset_y = raw_dataset_y.copy()\r\n",
        "dataset_y.tail()\r\n",
        "dataset_y.pop(\"id\")\r\n",
        "\r\n",
        "\r\n",
        "column_names_x = ['id']\r\n",
        "for i in range(1, 513):\r\n",
        "  column_names_x.append('x'+str(i))\r\n",
        "\r\n",
        "raw_x_data_emg = pd.read_csv('train_emg.csv', names=column_names_x,\r\n",
        "                      sep=\",\", skipinitialspace=True, skiprows=True)\r\n",
        "dataset_emg = raw_x_data_emg.copy()\r\n",
        "dataset_emg.tail()\r\n",
        "dataset_emg.pop(\"id\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "0            0\n1            1\n2            2\n3            3\n4            4\n         ...  \n64795    64795\n64796    64796\n64797    64797\n64798    64798\n64799    64799\nName: id, Length: 64800, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607281455116
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features=[]\r\n",
        "    \r\n",
        "for i in tqdm(range(64800)):\r\n",
        "    feature0 = ExtractFeatures(np.array(dataset_x_1[i,:]),np.array(dataset_x_2[i,:]),np.array(dataset_emg.iloc[i,:]))\r\n",
        "    features.append(feature0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 46224/64800 [30:40<12:03, 25.67it/s]"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607273548662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = pd.DataFrame(features)"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607284151437
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/plain": "(64800, 79)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 62,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607284152912
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features.to_csv(\"features_train.csv\", sep=',', index=False)"
      ],
      "outputs": [],
      "execution_count": 63,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607284170814
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}